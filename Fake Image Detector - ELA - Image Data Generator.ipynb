{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from pylab import *\n",
    "import re\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imlist(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.png') or f.endswith('.jpg') or f.endswith('.gif')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ela_image(image_mat):\n",
    "    resaved_filename = 'hehehe' + '.resaved.jpg'\n",
    "    ELA_filename = 'hehehe' + '.ela.png'\n",
    "    \n",
    "    im = Image.fromarray(np.uint8(image_mat * 255))\n",
    "    im.save(resaved_filename, 'JPEG', quality=95)\n",
    "    resaved_im = Image.open(resaved_filename)\n",
    "    \n",
    "    ela_im = ImageChops.difference(im, resaved_im)\n",
    "    \n",
    "    extrema = ela_im.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
    "#     print (\"Maximum difference was %d\" % (max_diff))\n",
    "    \n",
    "#     print(array(ela_im).shape)\n",
    "    return array(ela_im).reshape(128,128,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakes_datasets_filename = get_imlist('datasets/train/fake/')\n",
    "reals_datasets_filename = get_imlist('datasets/train/real/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_ela(image):\n",
    "    image = convert_to_ela_image(image)\n",
    "    image = image / 255.0\n",
    "    return(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13841 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 128\n",
    "\n",
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input_ela,\n",
    "                                   horizontal_flip=True,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2)\n",
    "\n",
    "data_generator_no_aug = ImageDataGenerator(\n",
    "                                    preprocessing_function=preprocess_input_ela\n",
    "                                    )\n",
    "\n",
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "        'datasets/train/',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=200,\n",
    "        class_mode='categorical')\n",
    "\n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input_ela)\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "        'datasets/validation/',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=200,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid', \n",
    "                 activation ='relu', input_shape = (128,128,3)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'valid', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/23 [===========================>..] - ETA: 4s - loss: 6.1601 - acc: 0.5980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agus/anaconda3/envs/cv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41487\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/agus/anaconda3/envs/cv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:747: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "cannot identify image file 'hehehe.resaved.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(uid, i)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \"\"\"\n\u001b[0;32m--> 401\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m   1262\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m-> 1263\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1738\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1739\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras_preprocessing/image.py\u001b[0m in \u001b[0;36mstandardize\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-4d7387109d93>\u001b[0m in \u001b[0;36mpreprocess_input_ela\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_input_ela\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_ela_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-295359f5ef39>\u001b[0m in \u001b[0;36mconvert_to_ela_image\u001b[0;34m(image_mat)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresaved_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'JPEG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresaved_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresaved_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2621\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2622\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file 'hehehe.resaved.jpg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-0570e196d5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         validation_steps=5)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    209\u001b[0m                             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                             max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m    212\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1478\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: cannot identify image file 'hehehe.resaved.jpg'"
     ]
    }
   ],
   "source": [
    "# Fit Model Here\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=23,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f6a4335f6c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the loss and accuracy curves for training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlegend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshadow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
